{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Web scrapping\n",
        "\n",
        "import requests\n",
        "\n",
        "# Login credentials\n",
        "username = \"Guest\"\n",
        "password = \"FG_WM\"\n",
        "\n",
        "# Login URL\n",
        "login_url = \"https://www.wm.tu-darmstadt.de/mat-db/signin.php\"\n",
        "\n",
        "# Session object to persist cookies across requests\n",
        "session = requests.Session()\n",
        "\n",
        "# Login payload\n",
        "login_payload = {\n",
        "    \"login\": username,\n",
        "    \"password\": password\n",
        "}\n",
        "\n",
        "# Send POST request to login\n",
        "login_response = session.post(login_url, data=login_payload)\n",
        "\n",
        "# Check if login was successful\n",
        "if login_response.status_code == 200:\n",
        "    print(\"Login successful!\")\n",
        "\n",
        "    # URLs of the pages\n",
        "    base_url = \"https://www.wm.tu-darmstadt.de/mat-db/view.php?id=\"\n",
        "    start_id = 1\n",
        "    end_id = 918\n",
        "\n",
        "    # Fetch HTML content for each page and save it as text\n",
        "    for page_id in range(start_id, end_id + 1):\n",
        "        url = base_url + str(page_id)\n",
        "        response = session.get(url)  # Use the session object for requests to maintain login session\n",
        "        if response.status_code == 200:\n",
        "            html_content = response.text\n",
        "\n",
        "            # Save HTML content to a text file\n",
        "            output_file = f'output_page_{page_id}.txt'\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                f.write(html_content)\n",
        "\n",
        "            print(f\"Page {page_id} content saved to {output_file}\")\n",
        "        else:\n",
        "            print(f\"Failed to fetch page {page_id}\")\n",
        "\n",
        "    # Further requests can be made using the session object\n",
        "    # For example:\n",
        "    # response = session.get(\"https://www.wm.tu-darmstadt.de/mat-db/your_desired_page.php\")\n",
        "else:\n",
        "    print(\"Login failed.\")"
      ],
      "metadata": {
        "id": "xbhIZcGuQcjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeDc6CLHOcW5"
      },
      "outputs": [],
      "source": [
        "## Organize extract the database\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# Initialize variables to store extracted data\n",
        "all_data = []\n",
        "\n",
        "# Define the property names to search for\n",
        "property_names = [\"E\", \"Rp0.2\", \"Rm\", \"A5\", \"Z\", \"ν\", \"K\", \"n\", \"σf\", \"εf\", \"R′p0.2\", \"σE\", \"εE\", \"NE\", \"NT\", \"Tσ\", \"Tεp\", \"K′\", \"n′\", \"σ′f\", \"ε′f\", \"b\", \"c\"]\n",
        "elements = ['C', 'Mn', 'P', 'S', 'N', 'Cu', 'Fe', 'Al', 'Ni', 'Mo', 'Si', 'Cr']\n",
        "\n",
        "# Iterate over all the files\n",
        "for i in range(1, 3):  # assuming files are named 'output_page_1.txt' to 'output_page_20.txt'\n",
        "    filename = f'output_page_{i}.txt'\n",
        "    with open(filename, 'r') as file:\n",
        "        html_content = file.read()\n",
        "\n",
        "    # Create a BeautifulSoup object\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Initialize variables to store extracted data for this file\n",
        "    properties = {}\n",
        "    chemical_composition = {}\n",
        "    heat_treatment_value = None\n",
        "\n",
        "    # Find the mechanical properties table\n",
        "    properties_table = soup.find('table', width='100%')\n",
        "    if properties_table:\n",
        "        rows = properties_table.find_all('tr')\n",
        "        for row in rows:\n",
        "            cells = row.find_all('td')\n",
        "            if len(cells) == 4:\n",
        "                property_name = cells[0].text.strip()\n",
        "                if property_name in property_names:\n",
        "                    property_value = cells[2].text.strip()\n",
        "                    properties[property_name] = property_value\n",
        "\n",
        "    # Find the chemical composition table\n",
        "    composition_table = soup.find('table', width='550')\n",
        "    if composition_table:\n",
        "        rows = composition_table.find_all('tr')\n",
        "        for row in rows:\n",
        "            cells = row.find_all('td')\n",
        "            if len(cells) == 12:\n",
        "                for i, element in enumerate(elements):\n",
        "                    chemical_composition[element] = cells[i].text.strip()\n",
        "\n",
        "    # Find Heat treatment value\n",
        "    td_elements = soup.find_all('td')\n",
        "    for td in td_elements:\n",
        "        if 'Heat treatment:' in td.text:\n",
        "            next_sibling_td = td.find_next_sibling('td')\n",
        "            if next_sibling_td is not None:\n",
        "                heat_treatment_value = next_sibling_td.text.strip()\n",
        "                break\n",
        "\n",
        "    # Store the extracted data for this file\n",
        "    all_data.append({\n",
        "        'File': filename,\n",
        "        'Properties': properties,\n",
        "        'Chemical Composition': chemical_composition,\n",
        "        'Heat Treatment': heat_treatment_value\n",
        "    })\n",
        "\n",
        "# Write the extracted data to a CSV file\n",
        "with open('chemical_and_mechanical_properties.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "\n",
        "    # Write header for chemical composition, mechanical properties, and heat treatment\n",
        "    header_row = ['File'] + elements + property_names + ['Heat Treatment']\n",
        "    writer.writerow(header_row)\n",
        "\n",
        "    # Write data for each file\n",
        "    for data in all_data:\n",
        "        row = [data['File']]\n",
        "        row += [data['Chemical Composition'].get(element, '') for element in elements]\n",
        "        row += [data['Properties'].get(prop, '') for prop in property_names]\n",
        "        row.append(data['Heat Treatment'])\n",
        "        writer.writerow(row)"
      ]
    }
  ]
}